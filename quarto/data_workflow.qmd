---
title: "Data WorkFlow"
author: "Filippo Dall'Olio"
format: 
  html:
    page-layout: full
editor: visual
editor_options: 
  chunk_output_type: inline
---

# Preparation

## Pakages

First, I load the required packages.

```{r}
devtools::install_github("f-dallolio/adtabler", quiet = TRUE)

library(tidyverse, quietly = TRUE)
library(tsibble, quietly = TRUE)
library(rlang, quietly = TRUE)
library(glue, quietly = TRUE)
library(adtabler, quietly = TRUE)
```

## Helper Functions:

### Strings

```{r}
#| output: false
# Ignore cases. Useful in e.g. str_detect()
no_case <- function(pattern) {
  stringr::regex(pattern, ignore_case = TRUE)
}

# Pad  integers with zero.
numpad <- function(x, width = NULL) {
  stopifnot(is.numeric(x))
  if (is.null(x)) {
    width <- max(nchar(as.character(x)))
  }
  stringr::str_pad(
    string = x,
    width = width,
    side = "left",
    pad = "0",
  )
}
# Shorthand with max padding of 2. Useful for months, days, hours, etc.
numpad2 <- function(x) {
  numpad(x, width = 2)
}
# Shorthand with max padding of 4. Useful for years
numpad4 <- function(x) {
  numpad(x, width = 4)
}
```

### Dates

```{r}
make_yearweek2 <- function(year, week = NULL, week_start = getOption("lubridate.week.start", 1)) {
  if (is.null(week)) {
    out <- map(year, ~ tsibble::make_yearweek(.x, 1:(52 + tsibble::is_53weeks(.x)), week_start))
  } else {
    out <- map(year, ~ tsibble::make_yearweek(year = .x, week = week, week_start))
  }
  return(out[[1]])
}
```

```{r}
date_to_yweek <- function(x, w_day = TRUE, week_start = getOption("lubridate.week.start", 1)){
  x <- as.Date(x)
  
  if(w_day){
    wd_n <- lubridate::wday(x, week_start = week_start) |> numpad2()
    wd_c <- lubridate::wday(x, label = TRUE, abbr = TRUE, week_start = week_start)
    
    out <- tsibble::yearweek(x, week_start = week_start) |> 
      paste0(" D", wd_n, " (", wd_c, ")")
    out[is.na(x)] <- NA
    return(out)
  }
  tsibble::yearweek(x, week_start = week_start)
}
```

```{r}
yweek_to_date_i <- function(x, week_start = getOption("lubridate.week.start", 1)){
  if(is.na(x)){
    return(NA)
  }
  x0 <- as.character(x) |> strsplit(" ") |> unlist()
  n <- length(x0)
    x0 <- x0[1 : 3] |> 
      str_remove_all('[A-Z]') |> 
      as.integer() |> 
      as.list()
    names(x0) <- c("year", "week", "wday")
    
    out <- make_yearweek(year = x0$year, week = x0$week)
    return(as.Date(out) + x0$wday - 1)
}

yweek_to_date <- function(x, simplify = TRUE, week_start = getOption("lubridate.week.start", 1)){
  if(simplify){
    return(map(.x = x, .f = ~ yweek_to_date_i(.x)) |> purrr::list_c())
  }
  map(.x = x, .f = ~ yweek_to_date_i(.x))
}
```

### Data Check

Check if the dates in a file include somne of the previous year.

```{r}
# Non vectorized
check_previous_year_i <- function(file, year){
  
  file_name <- str_split_i(file, "/", -1)
  
  cmd_lgl <- glue("grep -E -m 1 -c '{year - 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character()  |> sprintf(shQuote(file))
  cmd_out <- glue("grep -E -o '{year - 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character() |> sprintf(shQuote(file))
  
  out_lgl <-  suppressWarnings(system(cmd_lgl, intern = TRUE) == "1")
  
  if(out_lgl){
    print(glue("There are {year - 1} dates in {year}'s '{ file_name }'. Fetching earliest."))
    t_start <- Sys.time()
    out <-  system(cmd_out, intern = TRUE) |> unique()
    t_end <- Sys.time()
    elapsed <- t_end - t_start
    print(elapsed)
    return(
      sort(out)[[1]]
    )
  } else {
    print(glue("There are no {year - 1} dates in {year}'s '{ file_name }'."))
    return(
      NA
      )
  }
}
min_date_year_i <- function(file, year){
  cmd_out <- glue("grep -E -o '{year}-01-[0-9][0-9]' %s") |>
    as.character() |>
    sprintf(shQuote(file))
  out_temp <- check_previous_year_i(file, year)
  if (is.na(out_temp)) {
    out <-  system(cmd_out, intern = TRUE) |>
      unique() |>
      sort() |>
      suppressWarnings()
    if(length(out) == 0){
      return(NA)
    } else {
      return(out[[1]])
    }
  } else {
    out_temp
  }
}

# Vectorized
check_previous_year <- Vectorize(check_previous_year_i, USE.NAMES = FALSE)
min_date_year <- Vectorize(min_date_year_i, USE.NAMES = FALSE)
```

Check if the dates in a file include some of the next year.

```{r}
# Non Vectorized
check_next_year_i <- function(file, year){
  
  file_name <- str_split_i(file, "/", -1)
  
  cmd_lgl <- glue("grep -E -m 1 -c '{year + 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character()  |> sprintf(shQuote(file))
  cmd_out <- glue("grep -E -o '{year + 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character() |> sprintf(shQuote(file))
  
  out_lgl <-  suppressWarnings(system(cmd_lgl, intern = TRUE) == "1")
  
  if(out_lgl){
    print(glue("There are {year + 1} dates in {year}'s '{ file_name }'. Fetching earliest."))
    t_start <- Sys.time()
    out <-  system(cmd_out, intern = TRUE) |> unique()
    t_end <- Sys.time()
    elapsed <- t_end - t_start
    print(elapsed)
    return(
      sort(out, decreasing = TRUE)[[1]]
    )
  } else {
    print(glue("There are no {year + 1} dates in {year}'s '{ file_name }'."))
    return(
      NA
    )
  }
}
max_date_year_i <- function(file, year){
  cmd_out <- glue("grep -E -o '{year}-12-[0-9][0-9]' %s") |>
    as.character() |>
    sprintf(shQuote(file))
  out_temp <- check_next_year_i(file, year)
  if (is.na(out_temp)) {
    out <-  system(cmd_out, intern = TRUE) |>
      unique() |>
      sort(decreasing = TRUE) |>
      suppressWarnings()
    if(length(out) == 0){
      return(NA)
    } else {
      return(out[[1]])
    }
  } else {
    out_temp
  }
}

# Vectorized
check_next_year <- Vectorize(check_next_year_i, USE.NAMES = FALSE)
max_date_year <- Vectorize(max_date_year_i, USE.NAMES = FALSE)
```

3.  Data Read

```{r}
# Read number of rows. 
# If header is TRUE, the number of rows does not includes the first line. 
# 
# adtabler::read_nrows(full_name, header = TRUE, list_out = FALSE, df_out = FALSE) 

# Extract header
read_header <- function(file, to_string = FALSE) {
  file_format <- file |>
    stringr::str_split_i("\\.", -1)

  if (file_format == "tsv") {
    sep <- "\t"
  } else if (file_format == "csv") {
    sep <- ","
  } else {
    sep <- ""
  }

  out <- data.table::fread(
    file = file,
    sep = sep,
    nrows = 1,
    header = FALSE
  ) |>
    unlist(use.names = FALSE)
  
  if(to_string) {
    return(paste(out, collapse = "__"))
  }
  out
}

# Extract first row
read_row1 <- function(file, to_string = FALSE) {
  file_format <- file |>
    stringr::str_split_i("\\.", -1)

  if (file_format == "tsv") {
    sep <- "\t"
  } else if (file_format == "csv") {
    sep <- ","
  } else {
    sep <- ""
  }

  out <- data.table::fread(
    file = file,
    sep = sep,
    nrows = 1
  ) |>
    unlist()
  
  if(to_string) {
    return(paste(out, collapse = "__"))
  }
  out
}
```

## Load Data (one year at the time)

Defina the directory containing the AdIntel folders and retrieve data paths:

```{r}
adintel_folder <- "/mnt/sata_data_1/adintel/ADINTEL_DATA_2010/"
adintel_files <- list.files(adintel_folder, recursive = TRUE, full.names = TRUE)
```

Then retrieve and describe file paths for static references:

```{r}
static_references <- adintel_files |>
  str_subset(pattern = no_case("master_file")) |>
  str_subset(pattern = no_case("latest")) |>
  as_tibble_col(column_name = "full_file_name") |>
  mutate(
    file_name = full_file_name |>
      str_split_i("/", -1),
    file_name_std = file_name |>
      str_split_i("\\.", -2) |>
      adtabler::rename_adintel()
  )
# static_references
```

Retrieve and describe file paths for "dynamic" files (i.e. they can change year by year):

```{r}
dyn_files <- adintel_files |>
  str_subset(pattern = no_case("master_file"), negate = TRUE) |>
  as_tibble_col("full_file_name") |>
  mutate(
    year = full_file_name |>
      str_split_i("/", -3) |>
      as.integer(),
    file_type = full_file_name |>
      str_split_i("/", -2),
    file_name = full_file_name |>
      str_split_i("/", -1),
    file_name_std = file_name |>
      str_split_i("\\.", -2) |>
      rename_adintel()
  )
# dyn_files
```

Retrieve file paths for different types of data. First check unique file_type names. Here the output is the renamed/standardized names vector of file_type names with the originals as names.

```{r}
dyn_files$file_type |>
  unique() |>
  rename_adintel() |>
  set_names(dyn_files$file_type |> unique())
```

### Occurrences

```{r}
occurrences_files <- dyn_files |>
  filter(str_detect(file_type, no_case("occurrences"))) |>
  # rename(nielsen_file_name = file_name) |> 
  mutate(
    n_rows = read_nrows(full_file_name),
    min_date = min_date_year(full_file_name, year),
    max_date = max_date_year(full_file_name, year),
    col_names_og = full_file_name |>
      map_vec(
        ~ read_header(.x) |>
          paste(collapse = "___")
      ),
    col_names = full_file_name |>
      map_vec(
        ~ read_header(.x) |>
          rename_adintel() |>
          paste(collapse = "___")
      )
  )
```

```{r}
occurrences_files$col_names |> 
  str_split("___") |> 
  unlist() |> 
  unique()
```

```{r}
media_type_table |> 
  transmute(file_name = nielsen_file_name, 
            media_type_id,
            unique_key) |> 
  nest(unique_key = unique_key) |> 
  mutate(unique_key = unique_key |> 
           map(~ .x[[1]] |>  paste(collapse = "___")) |> 
           list_c()) |> 
  distinct() |> 
  nest(media_type_id = media_type_id) |> 
  left_join(occurrences_files) |> 
  unnest(everything())
```

### References

```{r}
# Filter file paths
references_files <- dyn_files |>
  filter(str_detect(file_type, no_case("references")))
```

Retrieve file's number of rows.

```{r}
references_files <- references_files |>
  mutate(nrows = full_file_name)

full_name <- references_files$full_file_name[[1]]
```

### Impressions

```{r}
impressions_files <- dyn_files |>
  filter(str_detect(file_type, no_case("impressions")))
```

### Market Breaks

```{r}
market_breaks_files <- dyn_files |>
  filter(str_detect(file_type, no_case("market_breaks")))
```

### Universe Estimates

```{r}
universe_estimates_files <- dyn_files |>
  filter(str_detect(file_type, no_case("universe_estimates")))
```
