---
title: "Data WorkFlow"
author: "Filippo Dall'Olio"
format: 
  html:
    page-layout: full
editor: visual
editor_options: 
  chunk_output_type: inline
---

# Preparation

## Pakages

First, I load the required packages.

```{r}
devtools::install_github("f-dallolio/adtabler", quiet = TRUE)

library(tidyverse, quietly = TRUE)
library(tsibble, quietly = TRUE)
library(rlang, quietly = TRUE)
library(glue, quietly = TRUE)
library(adtabler, quietly = TRUE)
```

## Helper Functions:

### Strings

```{r}
#| output: false
# Ignore cases. Useful in e.g. str_detect()
no_case <- function(pattern) {
  stringr::regex(pattern, ignore_case = TRUE)
}

# Pad  integers with zero.
numpad <- function(x, width = NULL) {
  stopifnot(is.numeric(x))
  if (is.null(x)) {
    width <- max(nchar(as.character(x)))
  }
  stringr::str_pad(
    string = x,
    width = width,
    side = "left",
    pad = "0",
  )
}
# Shorthand with max padding of 2. Useful for months, days, hours, etc.
numpad2 <- function(x) {
  numpad(x, width = 2)
}
# Shorthand with max padding of 4. Useful for years
numpad4 <- function(x) {
  numpad(x, width = 4)
}
```

### Dates

```{r}
make_yearweek2 <- function(year, week = NULL, week_start = getOption("lubridate.week.start", 1)) {
  if (is.null(week)) {
    out <- map(year, ~ tsibble::make_yearweek(.x, 1:(52 + tsibble::is_53weeks(.x)), week_start))
  } else {
    out <- map(year, ~ tsibble::make_yearweek(year = .x, week = week, week_start))
  }
  return(out[[1]])
}
```

```{r}
date_to_yweek <- function(x, w_day = TRUE, week_start = getOption("lubridate.week.start", 1)){
  x <- as.Date(x)
  
  if(w_day){
    wd_n <- lubridate::wday(x, week_start = week_start) |> numpad2()
    wd_c <- lubridate::wday(x, label = TRUE, abbr = TRUE, week_start = week_start)
    
    out <- tsibble::yearweek(x, week_start = week_start) |> 
      paste0(" D", wd_n, " (", wd_c, ")")
    out[is.na(x)] <- NA
    return(out)
  }
  tsibble::yearweek(x, week_start = week_start)
}
```

```{r}
yweek_to_date_i <- function(x, week_start = getOption("lubridate.week.start", 1)){
  if(is.na(x)){
    return(NA)
  }
  x0 <- as.character(x) |> strsplit(" ") |> unlist()
  n <- length(x0)
    x0 <- x0[1 : 3] |> 
      str_remove_all('[A-Z]') |> 
      as.integer() |> 
      as.list()
    names(x0) <- c("year", "week", "wday")
    
    out <- make_yearweek(year = x0$year, week = x0$week)
    return(as.Date(out) + x0$wday - 1)
}

yweek_to_date <- function(x, simplify = TRUE, week_start = getOption("lubridate.week.start", 1)){
  if(simplify){
    return(map(.x = x, .f = ~ yweek_to_date_i(.x)) |> purrr::list_c())
  }
  map(.x = x, .f = ~ yweek_to_date_i(.x))
}
```

### Data Check

Check if the dates in a file include somne of the previous year.

```{r}
# Non vectorized
check_previous_year_i <- function(file, year){
  
  file_name <- str_split_i(file, "/", -1)
  
  cmd_lgl <- glue("grep -E -m 1 -c '{year - 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character()  |> sprintf(shQuote(file))
  cmd_out <- glue("grep -E -o '{year - 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character() |> sprintf(shQuote(file))
  
  out_lgl <-  suppressWarnings(system(cmd_lgl, intern = TRUE) == "1")
  
  if(out_lgl){
    print(glue("There are {year - 1} dates in {year}'s '{ file_name }'. Fetching earliest."))
    t_start <- Sys.time()
    out <-  system(cmd_out, intern = TRUE) |> unique()
    t_end <- Sys.time()
    elapsed <- t_end - t_start
    print(elapsed)
    return(
      sort(out)[[1]]
    )
  } else {
    print(glue("There are no {year - 1} dates in {year}'s '{ file_name }'."))
    return(
      NA
      )
  }
}
min_date_year_i <- function(file, year){
  cmd_out <- glue("grep -E -o '{year}-01-[0-9][0-9]' %s") |>
    as.character() |>
    sprintf(shQuote(file))
  out_temp <- check_previous_year_i(file, year)
  if (is.na(out_temp)) {
    out <-  system(cmd_out, intern = TRUE) |>
      unique() |>
      sort() |>
      suppressWarnings()
    if(length(out) == 0){
      return(NA)
    } else {
      return(out[[1]])
    }
  } else {
    out_temp
  }
}

# Vectorized
check_previous_year <- function(file, year){
  purrr::map2(file, year, ~ check_previous_year_i(file = .x, year = .y)) |> 
    purrr::list_c()
}
min_date_year <- function(file, year){
  purrr::map2(file, year, ~ min_date_year_i(file = .x, year = .y)) |> 
    purrr::list_c()
}
```

Check if the dates in a file include some of the next year.

```{r}
# Non Vectorized
check_next_year_i <- function(file, year){
  
  file_name <- str_split_i(file, "/", -1)
  
  cmd_lgl <- glue("grep -E -m 1 -c '{year + 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character()  |> sprintf(shQuote(file))
  cmd_out <- glue("grep -E -o '{year + 1}-[0-9][0-9]-[0-9][0-9]' %s") |> 
    as.character() |> sprintf(shQuote(file))
  
  out_lgl <-  suppressWarnings(system(cmd_lgl, intern = TRUE) == "1")
  
  if(out_lgl){
    print(glue("There are {year + 1} dates in {year}'s '{ file_name }'. Fetching earliest."))
    t_start <- Sys.time()
    out <-  system(cmd_out, intern = TRUE) |> unique()
    t_end <- Sys.time()
    elapsed <- t_end - t_start
    print(elapsed)
    return(
      sort(out, decreasing = TRUE)[[1]]
    )
  } else {
    print(glue("There are no {year + 1} dates in {year}'s '{ file_name }'."))
    return(
      NA
    )
  }
}
max_date_year_i <- function(file, year){
  cmd_out <- glue("grep -E -o '{year}-12-[0-9][0-9]' %s") |>
    as.character() |>
    sprintf(shQuote(file))
  out_temp <- check_next_year_i(file, year)
  if (is.na(out_temp)) {
    out <-  system(cmd_out, intern = TRUE) |>
      unique() |>
      sort(decreasing = TRUE) |>
      suppressWarnings()
    if(length(out) == 0){
      return(NA)
    } else {
      return(out[[1]])
    }
  } else {
    out_temp
  }
}

# Vectorized
check_next_year <- function(file, year){
  purrr::map2(file, year, ~ check_next_year_i(file = .x, year = .y)) |> 
    purrr::list_c()
}
max_date_year <- function(file, year){
  purrr::map2(file, year, ~ max_date_year_i(file = .x, year = .y)) |> 
    purrr::list_c()
}
```

3.  Data Read

```{r}
# Read number of rows. 
# If header is TRUE, the number of rows does not includes the first line. 
# 
# adtabler::read_nrows(full_name, header = TRUE, list_out = FALSE, df_out = FALSE) 

# Extract header
read_header <- function(file, to_string = FALSE) {
  file_format <- file |>
    stringr::str_split_i("\\.", -1)

  if (file_format == "tsv") {
    sep <- "\t"
  } else if (file_format == "csv") {
    sep <- ","
  } else {
    sep <- ""
  }

  out <- data.table::fread(
    file = file,
    sep = sep,
    nrows = 1,
    header = FALSE
  ) |>
    unlist(use.names = FALSE)
  
  if(to_string) {
    return(paste(out, collapse = "__"))
  }
  out
}

# Extract first row
read_row1 <- function(file, to_string = FALSE) {
  file_format <- file |>
    stringr::str_split_i("\\.", -1)

  if (file_format == "tsv") {
    sep <- "\t"
  } else if (file_format == "csv") {
    sep <- ","
  } else {
    sep <- ""
  }

  out <- data.table::fread(
    file = file,
    sep = sep,
    nrows = 1
  ) |>
    unlist()
  
  if(to_string) {
    return(paste(out, collapse = "__"))
  }
  out
}
```

## Load Data (one year at the time)

Defina the directory containing the AdIntel folders and retrieve data paths:

```{r}
adintel_folder <- "/mnt/sata_data_1/adintel/ADINTEL_DATA_2010/"
adintel_files <- list.files(adintel_folder, recursive = TRUE, full.names = TRUE)
```

Retrieve and describe file paths for "dynamic" files (i.e. they can change year by year):

```{r}
dyn_files <- adintel_files |>
  str_subset(pattern = no_case("master_file"), negate = TRUE) |>
  as_tibble_col("full_file_name") |>
  mutate(
    file_size_mb = file.size(full_file_name)/(1024^2),
    file_size_mb = file_size_mb |> round(2),
    year = full_file_name |>
      str_split_i("/", -3) |>
      as.integer(),
    file_type = full_file_name |>
      str_split_i("/", -2),
    file_name = full_file_name |>
      str_split_i("/", -1),
    file_name_std = file_name |>
      str_split_i("\\.", -2) |>
      rename_adintel()
  )
# dyn_files
```

Retrieve file paths for different types of data. First check unique file_type names. Here the output is the renamed/standardized names vector of file_type names with the originals as names.

```{r}
dyn_files$file_type |>
  unique() |>
  rename_adintel() |>
  set_names(dyn_files$file_type |> unique())
```

### Occurrences

```{r}
occurrences_files <- dyn_files |>
  filter(str_detect(file_type, no_case("occurrences"))) |> 
  inner_join(occurrences_columns) |> 
  nest(col_pos = col_pos,
       col_name_man = col_name_man,
       col_class_man = col_class_man,
       col_p = col_p,
       col_n = col_n,
       descripton = description) |>
 mutate(col_pos = col_pos |> map(~.x[[1]]),
        col_name_man = col_name_man |> map(~.x[[1]]),
        col_class_man = col_class_man |> map(~.x[[1]]),
        col_p = col_p |> map(~.x[[1]]),
        col_n = col_n |> map(~.x[[1]]),
        descripton = descripton |> map(~.x[[1]]) )
```

Min and max dates.

```{r}
# occurrences_date <- occurrences_files |> 
#   select(full_file_name, year) |> 
#   distinct() |> 
#   mutate(
#     min_date = min_date_year(full_file_name, year),
#     max_date = max_date_year(full_file_name, year),
#   )
# occurrences_date_2010 <- occurrences_date
# write_rds(occurrences_date_2010, "~/Documents/r_wd/adtabler/data-raw/lookup_data/occurrences_date_2010.rds")
# usethis::use_data(occurrences_date_2010)
# occurrences_files$full_file_name |> rep(2)
```

### References

Retrieve info for dynamic references.

```{r}
dynamic_references_files <- dyn_files |>
  filter(str_detect(file_type, no_case("references"))) |> 
  mutate(
    n_rows = read_nrows(full_file_name),
    col_name_man = full_file_name |>
      map(
        ~ read_header(.x)
      )
  ) |> 
  unnest(everything()) |> 
  mutate(col_pos = seq_along(col_name_man), .by = file_name, .before = col_name_man)
```

Retrieve info for static references.

```{r}
static_references_files <- adintel_files |>
  str_subset(pattern = no_case("master_file")) |>
  str_subset(pattern = no_case("latest")) |>
  as_tibble_col(column_name = "full_file_name") |>
  mutate(
    file_size_mb = file.size(full_file_name)/(1024^2),
    file_size_mb = file_size_mb |> round(2),
    year = NA,
    file_type = "References",
    file_name = full_file_name |>
      str_split_i("/", -1),
    file_name_std = file_name |>
      str_split_i("\\.", -2) |>
      adtabler::rename_adintel(),
    n_rows = read_nrows(full_file_name),
    col_name_man = full_file_name |>
      map(
        ~ read_header(.x)
      )
  ) |> 
  unnest(everything()) |> 
  mutate(col_pos = seq_along(col_name_man), .by = file_name, .before = col_name_man)
```

Bind rows of static and dynamic references and merge with "reference_columns" (lookup table with info about all variables in references tables).

```{r}
references_columns
```

```{r}
references_files <- references_columns |> 
  inner_join(
    bind_rows(dynamic_references_files, static_references_files)
  ) |> 
  relocate(col_name_man : description, .after = col_pos) |> 
  relocate(file_name_std, .after = file_name) |> 
  nest(col_pos = col_pos,
       col_name_man = col_name_man,
       col_class_man = col_class_man,
       col_p = col_p,
       col_n = col_n,
       descripton = description) |>
 mutate(col_pos = col_pos |> map(~.x[[1]]),
        col_name_man = col_name_man |> map(~.x[[1]]),
        col_class_man = col_class_man |> map(~.x[[1]]),
        col_p = col_p |> map(~.x[[1]]),
        col_n = col_n |> map(~.x[[1]]),
        descripton = descripton |> map(~.x[[1]]) )

references_files
```

### Impressions

```{r}
impressions_files <- dyn_files |>
  filter(str_detect(file_type, no_case("impressions"))) |> 
  mutate(
    n_rows = read_nrows(full_file_name),
    col_name_man = full_file_name |>
      map(
        ~ read_header(.x)
      )
  ) |> 
  unnest(everything()) |> 
  mutate(col_pos = seq_along(col_name_man), .by = file_name, .before = col_name_man) |> 
  nest(col_pos = col_pos, 
       col_name_man = col_name_man) |> 
  mutate(col_pos = col_pos |> map(~.x[[1]]),
         col_name_man = col_name_man |> map(~.x[[1]]))
impressions_files
```

### Market Breaks

```{r}
market_breaks_files <- dyn_files |>
  filter(str_detect(file_type, no_case("market_breaks"))) |> 
  mutate(
    n_rows = read_nrows(full_file_name),
    col_name_man = full_file_name |>
      map(
        ~ read_header(.x)
      )
  ) |> 
  unnest(everything()) |> 
  mutate(col_pos = seq_along(col_name_man), .by = file_name, .before = col_name_man) |> 
  nest(col_pos = col_pos, 
       col_name_man = col_name_man) |> 
  mutate(col_pos = col_pos |> map(~.x[[1]]),
         col_name_man = col_name_man |> map(~.x[[1]]))
market_breaks_files
```

### Universe Estimates

```{r}
universe_estimates_files <- dyn_files |>
  filter(str_detect(file_type, no_case("universe_estimates"))) |> 
  mutate(
    n_rows = read_nrows(full_file_name),
    col_name_man = full_file_name |>
      map(
        ~ read_header(.x)
      )
  ) |> 
  unnest(everything()) |> 
  mutate(col_pos = seq_along(col_name_man), .by = file_name, .before = col_name_man) |> 
  nest(col_pos = col_pos, 
       col_name_man = col_name_man) |> 
  mutate(col_pos = col_pos |> map(~.x[[1]]),
         col_name_man = col_name_man |> map(~.x[[1]]))
universe_estimates_files
```
